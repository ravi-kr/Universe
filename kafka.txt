Apache Kafka

Distributed Message Streaming Platform
Service Source -> Messaging System -> Service Distribution
Point to Point Messaging System
Publish and Subscribe Messaging System

Point to Point Messaging System
Sender -> Queue -> Receiver

Publish-Subscribe
Publisher -> Topic -> Subscriber

Introduction
Features
Architecture
Key Terminologies
Installation and Pre-requisites
Setting up single-node Kafka Cluster
Setting up multi-node Kafka Cluster
Zookeeper
Setting up single-node Zookeeper
Setting up Zookeeper cluster
Producer details
Consumer details
Topic Creation and Alteration

Kafka Security
PLAINTEXT
SASL_PLAINTEXT
SSL (TLS encryption)
SASL_SSL

Java APIs
Producer API
Consumer API
Admin API

Cluster Monitoring
JMX exporter
Prometheus
Grafana

Producers (Topic/Partition) -> Kafka Cluster (Zookeeper Cluster) -> Consumers (Topic/Partition)

Distribution and Replication

Table = Topic
Finance

Producers
Brokers (Kafka servers)
Consumers

Zookeepers

Core APIs

Producer APIs
Consumer APIs
Stream APIs
Connector APIs
Admin APIs

Kafka Installation
Zookeeper Installation
Running single node Kafka cluster
Running single node Zookeeper cluster

Zookeeper install

tickTime=2000
initLimit=10
syncLimit=5
DataDir=/tmp/zookeeper
ClientPort=2181
maxClientCnxns=60
4lw.commands.whitelist=*

start in background
bin/zkServer.sh start
bin/zkServer.sh stop
echo stat | nc localhost 2181

then
Kafka (Scala/Java) install

broker.id=1
listeners=PLAINTEXT://localhost:9092
log.dirs=/tmp/kafka-logs
log.retention.hours=168
zookeeper.connect=localhost:2181

/bin/kafka-server-start.sh config/server.properties

echo dump | nc localhost 2181 | grep brokers

/bin/kafka-server-stop.sh

foreground run
background run

Create topics from command line

bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic myTopic --partitions 1 --replication-factor 1
bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic myTopic

Topic
Partition
Leader
Replicas
Isr (In sync replica)

bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic myTopic

bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic myTopic

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic myTopic --from-beginning

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic myTopic

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic myTopic --group myConsumerGroup

bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group console-consumer-65487

working with console producer
working with console consumer
commands to check topic properties and consumer group properties

3 zookeeper node cluster

tickTime=2000
initLimit=10
syncLimit=5
DataDir=/tmp/zookeeper-1
ClientPort=2181
maxClientCnxns=60
4lw.commands.whitelist=*

server.1=localhost:2788:3788
server.1=localhost:2888:3888
server.1=localhost:2988:3988

tickTime=2000
initLimit=10
syncLimit=5
DataDir=/tmp/zookeeper-2
ClientPort=2182
maxClientCnxns=60
4lw.commands.whitelist=*

server.1=localhost:2788:3788
server.1=localhost:2888:3888
server.1=localhost:2988:3988

tickTime=2000
initLimit=10
syncLimit=5
DataDir=/tmp/zookeeper-3
ClientPort=2183
maxClientCnxns=60
4lw.commands.whitelist=*

server.1=localhost:2788:3788
server.1=localhost:2888:3888
server.1=localhost:2988:3988

mkdir /tmp/zookeeper-3
mkdir /tmp/zookeeper-2
mkdir /tmp/zookeeper-1

echo 1 >> /tmp/zookeeper-1/myid
echo 2 >> /tmp/zookeeper-1/myid
echo 3 >> /tmp/zookeeper-1/myid

cat /tmp/zookeeper-1/myid
cat /tmp/zookeeper-2/myid
cat /tmp/zookeeper-3/myid

bin/zkServer.sh start-foreground 

echo stat | nc localhost 2181
echo stat | nc localhost 2182
echo stat | nc localhost 2183

3 kafka node cluster

broker.id=1
listeners=PLAINTEXT://localhost:9092
log.dirs=/tmp/kafka-logs-1
log.retention.hours=168
zookeeper.connect=localhost:2181,localhost:2182,localhost:2183

broker.id=2
listeners=PLAINTEXT://localhost:9093
log.dirs=/tmp/kafka-logs-2
log.retention.hours=168
zookeeper.connect=localhost:2181,localhost:2182,localhost:2183

broker.id=3
listeners=PLAINTEXT://localhost:9094
log.dirs=/tmp/kafka-logs-3
log.retention.hours=168
zookeeper.connect=localhost:2181,localhost:2182,localhost:2183

bin/kafka-server-start.sh config/server.properties

bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic Topic01 --partitions 1 --replication-factor 1

bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic Topic01

echo dump | nc localhost 2181 | grep brokers

bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --create --topic Topic02 --partitions 3 --replication-factor 3

Internals of Topics, Partitions and Replication

echo stat | nc localhost 2181
echo dump | nc localhost 2181

bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --create --topic myTopic --partitions 3 --replication-factor 2

bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic myTopic

NonExistentPartition
NewPartition
OnlinePartition
OfflinePartition

NonExistentReplica
NewReplica
OnlineReplica
OfflineReplica

Kafka Controller Node

bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --create --topic testTopic --partitions 1 --replication-factor 1

bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic testTopic

bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic testTopic --partitions 2

bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --topics-to-move-json-file topicsToMove.json --broker-list "2,3" --generate

bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file suggestedChange.json --execute

bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file suggestedChange.json --verify

round robin fashion

Internals of Producers and offsets in Kafka
Producer.send()

Log end offset
current offset
committed offset

Producer:
key
payload

Message:
key
payload
topic
partition
offset
timestamp

Internals of Producers and offsets in Kafka
max.poll.records=15
consumer.poll()
response - 15 records
consumer.commit()

Internals of consumer groups

Consumer group re-balancing

Group coordinator, Group leader, Rebalance internals
